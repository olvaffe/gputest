#version 460 core

/*
 * Copyright 2024 Google LLC
 * SPDX-License-Identifier: MIT
 */

#define BLOCK_SIZE_X 4
#define BLOCK_SIZE_Z 4

#extension GL_EXT_samplerless_texture_functions : enable
#extension GL_EXT_shader_explicit_arithmetic_types : enable
#extension GL_EXT_shader_image_load_formatted : enable
#extension GL_KHR_shader_subgroup_ballot : enable
#extension GL_EXT_shader_subgroup_extended_types_float16 : enable

layout(local_size_x = 16, local_size_y = 1, local_size_z = 16) in;

layout(set = 0, binding = 0) readonly buffer SSBO {
    f16vec4 weights[];
} ssbo;

layout(set = 0, binding = 1) uniform UBO {
    uint src_slice_count;
    uint dst_slice_count;
    uint grid_width;
    uint grid_height;
} ubo;

layout(set = 0, binding = 2) uniform texture2D src;
layout(set = 0, binding = 3) uniform image2D dst;

void main()
{
    const uint dst_x = gl_GlobalInvocationID.x * BLOCK_SIZE_X;
    const uint dst_y = gl_GlobalInvocationID.y;
    const uint dst_slice = gl_GlobalInvocationID.z * BLOCK_SIZE_Z;

    if (dst_x >= ubo.grid_width || dst_y >= ubo.grid_height || dst_slice >= ubo.dst_slice_count)
        return;

    f16vec4 res[BLOCK_SIZE_Z][BLOCK_SIZE_X];
    for (uint s = 0; s < BLOCK_SIZE_Z; s++) {
        for (uint x = 0; x < BLOCK_SIZE_X; x++)
            res[s][x] = f16vec4(0.0);
    }

    uint idx = dst_slice * ubo.src_slice_count * 4;
    for (uint src_slice = 0; src_slice < ubo.src_slice_count; src_slice++) {
        f16vec4 val[BLOCK_SIZE_X];
        for (uint x = 0; x < BLOCK_SIZE_X; x++) {
            val[x] = f16vec4(
                texelFetch(src, ivec2(dst_x + x, dst_y * ubo.src_slice_count + src_slice), 0));
        }

#if 1
        for (uint s = 0; s < BLOCK_SIZE_Z; s++) {
            for (uint x = 0; x < BLOCK_SIZE_X; x++) {
                res[s][x] += ssbo.weights[idx + 0] * val[x].x;
                res[s][x] += ssbo.weights[idx + 1] * val[x].y;
                res[s][x] += ssbo.weights[idx + 2] * val[x].z;
                res[s][x] += ssbo.weights[idx + 3] * val[x].w;
            }
            idx += 4;
        }
#else
#if BLOCK_SIZE_X != 1
#error "BLOCK_SIZE_X must be 1"
#endif
#if BLOCK_SIZE_Z != 8
#error "BLOCK_SIZE_Z must be 8"
#endif
	/* local size must be (>=32, 1, 1) too */

        f16vec4 w;
        if (gl_SubgroupInvocationID < BLOCK_SIZE_Z * 4)
            w = ssbo.weights[idx + gl_SubgroupInvocationID];
        idx += BLOCK_SIZE_Z * 4;

#define MATMUL(res, mat, vec, s)                             \
    res[s][0] += subgroupBroadcast(w, s * 4 + 0) * val[0].x; \
    res[s][0] += subgroupBroadcast(w, s * 4 + 1) * val[0].y; \
    res[s][0] += subgroupBroadcast(w, s * 4 + 2) * val[0].z; \
    res[s][0] += subgroupBroadcast(w, s * 4 + 3) * val[0].w
        MATMUL(res, w, val, 0);
        MATMUL(res, w, val, 1);
        MATMUL(res, w, val, 2);
        MATMUL(res, w, val, 3);
        MATMUL(res, w, val, 4);
        MATMUL(res, w, val, 5);
        MATMUL(res, w, val, 6);
        MATMUL(res, w, val, 7);

#endif
    }

    for (uint s = 0; s < BLOCK_SIZE_Z; s++) {
        if (dst_slice + s >= ubo.dst_slice_count)
            break;

        for (uint x = 0; x < BLOCK_SIZE_X; x++) {
            if (dst_x + x >= ubo.grid_width)
                break;
            imageStore(dst, ivec2(dst_x + 0, dst_y * ubo.dst_slice_count + dst_slice + s),
                       vec4(res[s][x]));
        }
    }
}
